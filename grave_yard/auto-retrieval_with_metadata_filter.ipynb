{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index-vector-stores-chroma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "chroma_client = chromadb.EphemeralClient()\n",
    "chroma_collection = chroma_client.create_collection(\"quickstart\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = chroma_collection.get()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "\n",
    "chroma_vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "chroma_storage_context = StorageContext.from_defaults(vector_store=chroma_vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install llama-index-vector-stores-weaviate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U weaviate-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install llama-index llama-hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "populate index from csv doc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup Arize Phoenix for logging/observability\n",
    "import phoenix as px\n",
    "import llama_index.core\n",
    "\n",
    "px.launch_app()\n",
    "llama_index.core.set_global_handler(\"arize_phoenix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json \n",
    "import openai\n",
    "\n",
    "with open('openai.secret.json', 'r') as file:\n",
    "    secret = json.load(file)\n",
    "    os.environ[\"OPENAI_API_KEY\"] = secret['secret']\n",
    "    openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install llama-index-llms-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install llama-index-llms-huggingface-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install llama-index-embeddings-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "from llama_index.vector_stores.weaviate import WeaviateVectorStore\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import Settings\n",
    "\n",
    "\n",
    "client = weaviate.connect_to_local(\n",
    "    headers={\"X-OpenAI-Api-key\": os.getenv(\"OPENAI_API_KEY\")}\n",
    ")\n",
    "\n",
    "Settings.embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\"\n",
    ")\n",
    "Settings.chunk_size = 512\n",
    "Settings.chunk_overlap = 50\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.collections.delete(\"LlamaIndex_auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.vector_stores.weaviate import WeaviateVectorStore\n",
    "from llama_index.core import VectorStoreIndex, StorageContext\n",
    "\n",
    "vector_store = WeaviateVectorStore(\n",
    "    weaviate_client=client, index_name='Gov_opportunities'\n",
    ")\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index llama-index-readers-json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install span-marker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install llama-index-extractors-entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install python-dateutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "import json\n",
    "from dateutil import parser\n",
    "from llama_index.core.async_utils import run_jobs\n",
    "from llama_index.core import SummaryIndex\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.vector_stores import (\n",
    "    FilterOperator,\n",
    "    MetadataFilter,\n",
    "    MetadataFilters,\n",
    ")\n",
    "from llama_index.core.schema import IndexNode\n",
    "\n",
    "\n",
    "documents = SimpleDirectoryReader('/Users/haiyangliu/Workspace/gov_opportunity_new/content/opportunities/projects').load_data()\n",
    "doc_index = VectorStoreIndex.from_documents(\n",
    "    documents, storage_context=storage_context\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_index = VectorStoreIndex.from_documents(\n",
    "    documents, storage_context=chroma_storage_context\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def aprocess_doc(doc, include_summary: bool = True):\n",
    "    doc_object = json.loads(doc.text)\n",
    "    metadata = doc.metadata\n",
    "    new_metadata = {\n",
    "        \"project_id\": doc_object['ProjectID'],\n",
    "        'department': doc_object['Department/Ind.Agency'],\n",
    "        'naics_code': doc_object['NaicsCode'],\n",
    "        'psc_code': doc_object['ProductServiceCode'],\n",
    "        'sub_department': doc_object['Sub-Tier'],\n",
    "        'set_aside': doc_object['SetASide'],\n",
    "        'set_aside_code': doc_object['SetASideCode'],\n",
    "        'type': doc_object['Type'],\n",
    "        'place_of_performance_country': doc_object['PlaceOfPerformanceCountry'],\n",
    "        'place_of_performance_city': doc_object['PlaceOfPerformanceCity'],\n",
    "        'place_of_performance_state': doc_object['PlaceOfPerformanceState'],\n",
    "    }\n",
    "    if (doc_object['ResponseDueDate']):\n",
    "        due_date = parser.parse(doc_object['ResponseDueDate'])\n",
    "        new_metadata[\"due_date_year\"] = due_date.year\n",
    "        new_metadata[\"due_date_month\"] = due_date.month\n",
    "        new_metadata[\"due_date_day\"] = due_date.day\n",
    "\n",
    "    if (doc_object['PostedDate']):\n",
    "        posted_date = parser.parse(doc_object['PostedDate'])\n",
    "        new_metadata[\"posted_date_year\"] = posted_date.year\n",
    "        new_metadata[\"posted_date_month\"] = posted_date.month\n",
    "        new_metadata[\"posted_date_day\"] = posted_date.day\n",
    "\n",
    "    if include_summary:\n",
    "        summary_index = SummaryIndex.from_documents([doc])\n",
    "        query_str = \"Give a one-sentence concise summary of this project.\"\n",
    "        query_engine = summary_index.as_query_engine(\n",
    "            llm=OpenAI(model=\"gpt-3.5-turbo\")\n",
    "        )\n",
    "        summary_txt = await query_engine.aquery(query_str)\n",
    "        summary_txt = str(summary_txt)\n",
    "    else:\n",
    "        summary_txt = \"\"\n",
    "    # filter for the specific doc id\n",
    "    filters = MetadataFilters(\n",
    "        filters=[\n",
    "            MetadataFilter(\n",
    "                key=\"file_name\", operator=FilterOperator.EQ, value=metadata['file_name']\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    # create an index node using the summary text\n",
    "    index_node = IndexNode(\n",
    "        text=summary_txt,\n",
    "        metadata=new_metadata,\n",
    "        obj=doc_index.as_retriever(filters=filters),\n",
    "        index_id=doc.id_,\n",
    "    )\n",
    "\n",
    "    return index_node\n",
    "\n",
    "async def aprocess_docs(docs):\n",
    "    \"\"\"Process metadata on docs.\"\"\"\n",
    "\n",
    "    index_nodes = []\n",
    "    tasks = []\n",
    "    for doc in docs:\n",
    "        task = aprocess_doc(doc)\n",
    "        tasks.append(task)\n",
    "\n",
    "    index_nodes = await run_jobs(tasks, show_progress=True, workers=3)\n",
    "\n",
    "    return index_nodes \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in documents:\n",
    "    print(doc.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_nodes = await aprocess_docs(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in index_nodes:\n",
    "    print(node.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.vector_stores.weaviate import WeaviateVectorStore\n",
    "from llama_index.core import VectorStoreIndex, StorageContext\n",
    "\n",
    "class_name = \"LlamaIndex_auto\"\n",
    "\n",
    "vector_store_auto = WeaviateVectorStore(\n",
    "    weaviate_client=client, index_name=class_name\n",
    ")\n",
    "storage_context_auto = StorageContext.from_defaults(\n",
    "    vector_store=vector_store_auto\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import VectorStoreIndex, StorageContext\n",
    "\n",
    "class_name = \"LlamaIndex_auto_chroma\"\n",
    "\n",
    "vector_store_auto = ChromaVectorStore(\n",
    "    chroma_collection=chroma_collection\n",
    ")\n",
    "storage_context_auto = StorageContext.from_defaults(\n",
    "    vector_store=vector_store_auto\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.callbacks import (\n",
    "    CallbackManager,\n",
    "    LlamaDebugHandler,\n",
    "    CBEventType,\n",
    ")\n",
    "\n",
    "llama_debug = LlamaDebugHandler(print_trace_on_end=True)\n",
    "callback_manager = CallbackManager([llama_debug])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex(\n",
    "    objects=index_nodes, storage_context=storage_context_auto, callback_manager=callback_manager\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.vector_stores import MetadataInfo, VectorStoreInfo\n",
    "\n",
    "vector_store_info = VectorStoreInfo(\n",
    "    content_info=\"Government contract opportunities\",\n",
    "    metadata_info=[\n",
    "        MetadataInfo(\n",
    "            name=\"project_id\",\n",
    "            description=\"the unique identifier of this opportunity\",\n",
    "            type=\"string\",\n",
    "        ),\n",
    "        MetadataInfo(\n",
    "            name=\"department\",\n",
    "            description=\"The government department that published this opportunity\",\n",
    "            type=\"string\",\n",
    "        ),\n",
    "        MetadataInfo(\n",
    "            name=\"naics_code\",\n",
    "            description=\"NAICS Code. This code is maximum of 6 digits, also referred as Industry Classification Code\",\n",
    "            type=\"string\",\n",
    "        ),\n",
    "        MetadataInfo(\n",
    "            name=\"psc_code\",\n",
    "            description=\"Classification Code of this opportunity, also referred as Product Service Code or PSC Code for short\",\n",
    "            type=\"string\",\n",
    "        ),\n",
    "        MetadataInfo(\n",
    "            name=\"sub_department\",\n",
    "            description=\"Division or Sub-Department that published this opportunity\",\n",
    "            type=\"string\",\n",
    "        ),\n",
    "        MetadataInfo(\n",
    "            name=\"set_aside\",\n",
    "            description=\"Description of the Set Aside\",\n",
    "            type=\"string\",\n",
    "        ),\n",
    "        MetadataInfo(\n",
    "            name=\"set_aside_code\",\n",
    "            description=\"Code of the Set Aside field\",\n",
    "            type=\"string\",\n",
    "        ),\n",
    "        MetadataInfo(\n",
    "            name=\"type\",\n",
    "            description=\"Procurement Type of this opportunities\",\n",
    "            type=\"string\",\n",
    "        ),\n",
    "        MetadataInfo(\n",
    "            name=\"place_of_performance_country\",\n",
    "            description=\"Country of the Place of Performance for this project\",\n",
    "            type=\"string\",\n",
    "        ),\n",
    "        MetadataInfo(\n",
    "            name=\"place_of_performance_city\",\n",
    "            description=\"City of the Place of Performance for this project\",\n",
    "            type=\"string\",\n",
    "        ),\n",
    "        MetadataInfo(\n",
    "            name=\"place_of_performance_state\",\n",
    "            description=\"State of the Place of Performance for this project\",\n",
    "            type=\"string\",\n",
    "        ),\n",
    "        MetadataInfo(\n",
    "            name=\"due_date_year\",\n",
    "            description=\"The year of the Response Deadline date\",\n",
    "            type=\"integer\",\n",
    "        ),\n",
    "        MetadataInfo(\n",
    "            name=\"due_date_month\",\n",
    "            description=\"the month of the Response Deadline date\",\n",
    "            type=\"integer\",\n",
    "        ),\n",
    "        MetadataInfo(\n",
    "            name=\"due_date_day\",\n",
    "            description=\"the day of the Response Deadline date\",\n",
    "            type=\"integer\",\n",
    "        ),\n",
    "        MetadataInfo(\n",
    "            name=\"posted_date_year\",\n",
    "            description=\"Year of the Opportunity Posted Date\",\n",
    "            type=\"integer\",\n",
    "        ),\n",
    "        MetadataInfo(\n",
    "            name=\"posted_date_month\",\n",
    "            description=\"Month of the Opportunity Posted Date\",\n",
    "            type=\"integer\",\n",
    "        ),\n",
    "        MetadataInfo(\n",
    "            name=\"posted_date_day\",\n",
    "            description=\"day of the Opportunity Posted Date\",\n",
    "            type=\"integer\",\n",
    "        )\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.retrievers import VectorIndexAutoRetriever\n",
    "\n",
    "retriever = VectorIndexAutoRetriever(\n",
    "    index,\n",
    "    vector_store_info=vector_store_info,\n",
    "    similarity_top_k=2,\n",
    "    empty_query_top_k=10,  # if only metadata filters are specified, this is the limit\n",
    "    verbose=True,\n",
    "    callback_manager=callback_manager\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import QueryBundle\n",
    "\n",
    "nodes = retriever.retrieve(QueryBundle(\"find me opportunities about plumbing\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = retriever.retrieve(QueryBundle(\"Find me the projects from Department of Defense\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_retriever = doc_index.as_retriever()\n",
    "old_nodes = old_retriever.retrieve(\"find me plumbing related projects\")\n",
    "for old_node in old_nodes:\n",
    "    print(old_node.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in nodes:\n",
    "    print(node.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "query_engine = RetrieverQueryEngine.from_args(retriever, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(\"find me plumbing related projects\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gov_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
